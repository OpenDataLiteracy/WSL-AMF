{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download json records for all published datasets\n",
    "\n",
    "This should work for any socrata portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries\n",
    "import csv\n",
    "import requests\n",
    "import json as json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the code for your portal of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeturl='https://data.wa.gov/' #change this to the SOCRATA portal you want to target, don't forget ending /\n",
    "descriptor='WA'   #change this to a recognizable descriptor for yourself- used in csv filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dictionary of dcat records\n",
    "Use the Socrata API to get basic metadata for the public assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=requests.get(targeturl+\"api/dcat.json\") #build string according to SOCRATA's convention to get public data assets\n",
    "j=json.loads(r.text) #parse the json into a list named j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#j[0] #view the first record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Pit\n",
    "\n",
    "Ignore this block.  Use it to test out things or store bits of unused code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The indexes for i (below) are much more limited than the indexes for j\n",
    "test=[] #test list to fill\n",
    "\n",
    "for i in j:\n",
    "    #for x in i:\n",
    "        if i.get('format') == 'text/csv':\n",
    "            t = i.get('identifier')\n",
    "            test.append(t)\n",
    "            #print(i.get('format'))\n",
    "test.sort()\n",
    "print(test[0:20])\n",
    "\n",
    "\n",
    "#print(len(test))\n",
    "#j[0].keys() #Shows keys\n",
    "#type(j['identifier'])\n",
    "#print(j[0]['format'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of all the uids that are datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List built: 551 elements\n"
     ]
    }
   ],
   "source": [
    "masterlist=[] #dim masterlist as a empty list\n",
    "\n",
    "for i in j:  #j is the dictionary of parsed json\n",
    "        if len(i['identifier'])==9: #Basically, is the identifier legitimate?\n",
    "            if i.get('format')=='text/csv':  #select only datasets (not pdfs or external links)\n",
    "                uid=i['identifier']\n",
    "                masterlist.append(uid)\n",
    "\n",
    "\n",
    "masterlist.sort() #sort masterlist\n",
    "print(\"List built:\", len(masterlist),\"elements\") #print how many elements are in masterlist\n",
    "#print(masterlist[0:100]) See the first hundred if you want to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to see the list of urls for metadata, run this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in masterlist:\n",
    "    print(targeturl+'views/'+m+'.json') #build string according to SOCRATA's convention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a csv of the metadata\n",
    "\n",
    "Basic order of operations:\n",
    "Set up csv file with titles\n",
    "For loop to cycle through masterlist of dataset ids from above\n",
    "\n",
    "    Retrieve json file\n",
    "    Count the number of columns\n",
    "    Count the number of non empty column desctiptions\n",
    "    Write elements to csv file, convert the dates, and tack on the two count values\n",
    "\n",
    "Here are the columns: 'id','name','description','category','downloadCount','viewCount','licenseId','publicationDate','rowsUpdateAt','tags','rowLabel','numberColumns','numColumnDescriptions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "916 of 916 rows written, 0 remaining\n"
     ]
    }
   ],
   "source": [
    "metadata=open(descriptor+' - METADATA.csv', 'w', newline='')\n",
    "csv.writer(metadata).writerow(['id','name','description','category','downloadCount','viewCount','licenseId','publicationDate','rowsUpdateAt','tags'])\n",
    "\n",
    "metadata=open(descriptor+' - METADATA.csv', 'w', newline='')\n",
    "csv.writer(metadata).writerow(['id','name','description','category','downloadCount','viewCount','licenseId','publicationDate','rowsUpdateAt','tags','rowLabel','numberColumns','numColumnDescriptions'])\n",
    "for s in masterlist:\n",
    "    s=requests.get(targeturl+'views/'+s+'.json') #build string according to SOCRATA's convention\n",
    "    r=json.loads(s.text)\n",
    "    \n",
    "    colnum = len(r['columns']) #Get number of columns\n",
    "    \n",
    "    count = 0\n",
    "    for q in r['columns']:  #Tally the number of col descriptions that contain a description\n",
    "        if q.get('description','') != '': #If the description key doesn't exist, default value is '' (don't know why some don't have the key)\n",
    "            count += 1\n",
    "    coldesc = count\n",
    "    #write the values to the csv file. Dates in json files are seconds from jan 1 1970 so datetime.datetime.fromtimestamp converts\n",
    "    csv.writer(metadata).writerow([r['id'].encode(\"utf-8\"),r['name'].encode(\"utf-8\"),r.get('description','N/A'),r.get('category','N/A'),r['downloadCount'],r['viewCount'],r.get('LicenseID','N/A'),datetime.datetime.fromtimestamp(r['publicationDate']),datetime.datetime.fromtimestamp(r['rowsUpdatedAt']),r.get('tags','N/A'),r['metadata'].get('rowLabel','N/A'),colnum,coldesc]) #write one line to csv file\n",
    "\n",
    "metadata.close() #Close the output file, release all locks\n",
    "print(len(j)-1,\"of\",len(j)-1,\"rows written, 0 remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
