## Planning Assessment Strategy

The complete catalog, or just the datasets, can be assessed for the following:

- Percent overall metadata completeness
- Percent with a description
- Download statistics by publisher
- Number of links to related content (views etc.)
- Total views of dataset plus related content


### A Sample of Datasets

A sample of datasets will be used to assess more granular aspects such as aboutness and clarity in description.

Aiming for 25% or ~125 datasets as a sample.  I will use a stratified random sample design:  The list of datasets will be divided into
three levels based on the number of downloads and ~40 datasets from each level (distributed across 4 two-year groups) will be randomly selected and evaluated based on the variables listed below.

Use Kubler et al. (2018) framework? 


Or Umbrich et al. (2015)?

The European Open Data Portal Monitor assesses metadata completeness by these variables:
    
> licence, author, organisation, date released and date updated 

There is also the open government benchmark proposed by [VeljkoviÂ´c et al. (2014)](https://www.sciencedirect.com/science/article/pii/S0740624X14000434)

### Variables

- File format
- Publishing Agency
- Number of downloads
- Date of publication
- Date updated
- Date metadata updated
- Percent column descriptions complete
- Is this a one year dataset that is part of ongoing data collection?
- Is the dataset description rich but understandable?


I should assess based on the [5-stars](https://www.europeandataportal.eu/elearning/en/module10/#/id/co-01)


### Sample of datasets for assessment

- Took 115 datasets from 12 groupings: 
 - Number of Downloads (<100, >101 but <1500, >1500)
 - Year Created (2012/2013, 2014/2015, 2016,2017, 2018,2019)

Assessment: Assess relevant variables on a 4 point scale: 0 = not present, 1 = no, 2 = somewhat, 3 = yes

1. Check to make sure dataset is still published
2. Title Understandable?
3. Description Helpful?
4. Keywords Useful?

### Questions
