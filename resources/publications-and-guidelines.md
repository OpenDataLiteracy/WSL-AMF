## Academic Sources

**Academic sources relating to assessment of data portals**

[Machova and Lnenicka 2017 Evaluating the Quality of Open Data...](https://pdfs.semanticscholar.org/30d3/c97ed33dff97601142476859370784f9ad76.pdf) - pg 27 has a nice review of assessment

[Kubler et al. 2018 metadata quality assessment](http://www.sciencedirect.com/science/article/pii/S0740624X16301319)

[Neumaier et al 2017 Automated method of assessing metadata](http://doi.acm.org/10.1145/2964909)

[Bright et al. 2015](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2613853)- Tackles the problem of black box use of OGD. Cites something suggesting privatce citizen use of data is likely small, proxy organizations are the key.  They assessed metadata richness by number of tags and length of description. This paper has good references but I think their work is flawed- does not actually identify reasons for downloads, only relationships b/t downloads and other factors, correlation, no causation!

[Correa et al 2019](https://www.sciencedirect.com/science/article/pii/S0740624X18305185?dgcid=rss_sd_all)- looks at ways to find data in the 'deep web' hidden by poorly implemented data portals.

[Kucera et al. 2013](https://link.springer.com/chapter/10.1007%2F978-3-642-40160-2_13)- an early assessment of quality in OGD portals around the world- requested and received through ILL.

[Veljkovic et al. 2014](https://www.sciencedirect.com/science/article/pii/S0740624X14000434).  Assesses data.gov. Puts metadata completeness in a larger category of data openess and gives the portal a value of 67.5%.  Pretty confusing paper.  The only element they include for completeness is description. 

*From Nic*

Data quality assessment of maintenance reporting procedures. (2016). Expert Systems with Applications, 63, [145–164.](https://doi.org/10.1016/j.eswa.2016.06.043) -Very similar to Neumaier et al but with business branch maintenance reporting. Technical.

[Geiger and Lucke 2012](https://jedem.org/index.php/jedem/article/view/143) - An older paper about state open data.  Cites the 10 fundementals of OGD from Sunlight Foundation. Talks about paradigm shift from default closed data to default open data. Does a SWOT analysis on OGD.

Mitlöhner, J., Neumaier, S., Umbrich, J., & Polleres, A. (2016). Characteristics of Open Data CSV Files. 2016 2nd International Conference on Open and Big Data (OBD), [72–79.](https://doi.org/10.1109/OBD.2016.18)

Umbrich, J., Neumaier, S., & Polleres, A. (2015). Quality Assessment and Evolution of Open Data Portals. 2015 3rd International Conference on Future Internet of Things and Cloud, [404–411.](https://doi.org/10.1109/FiCloud.2015.82) -  This is a nice analysis of ckan portals.  Their online system does not seem to be in existence anymore.  They look at core metadata values and avaialble ones.  Their core ones are the [defaults offered by ckan](https://docs.ckan.org/en/2.8/user-guide.html): title, description, tags, license, organization.  THe only required field is title but ckan suggests adding a description and license at the minimum.

Veljkovic et al. (n.d.). Municipal Open Data Challenges. In CeDEM11. Retrieved [from](https://books.google.com/books?hl=en&lr=&id=4pKT1R0DfToC&oi=fnd&pg=PA195&dq=%22open+data%22+state+level+&ots=DQloB6ejU7&sig=xv_VTqTlq63w-_ClN8AdL_N8f0#v=onepage&q=%22open%20data%22%20state%20level&f=false)

Vetrò, A., Canova, L., Torchiano, M., Minotas, C. O., Iemma, R., & Morando, F. (2016). Open data quality measurement framework: Definition and application to Open Government Data. Government Information Quarterly, 33(2), [325–337.](https://www.sciencedirect.com/science/article/pii/S0740624X16300132) - Identifies assessment metrics specifically for OGD.  Tests effectiveness on a high quality portal and low quality portal. However, small sample size.  Also, some metrics are very subjective.  Ran 14 tests and did not adjust p-value.  Found that understandability was a big problem.  Has a nice table showing how each metric was computed.  They did what I'm going to do: automated for some, manual data collection for other.

**Other Academic Sources**

[Kucera et al. 2015](http://ceur-ws.org/Vol-1343/paper5.pdf) - overview of open data publishing

**Open Data Guidelines and Reports**

[Open Data Policy Hub](https://opendatapolicyhub.sunlightfoundation.com/guidelines/)

[European open data recommendations 2017](https://www.europeandataportal.eu/en/what-we-do/factsheets-and-reports)

[European open data](https://www.europeandataportal.eu/sites/default/files/edp_landscaping_insight_report_n4_2018.pdf) discusses state of portals.
- Page 28 is start of chapter on assessing portals.  Just reports basic analytics for protal usage though.
- Page 36 shows popular data domains for pubishers.
- Has good examples of portal impact

[European Open Data Monitor](https://www.opendatamonitor.eu/frontend/web/index.php?r=dashboard%2Findex)

[Showell ODL project](https://github.com/OpenDataLiteracy/CityOfSeattle-2017/blob/master/SeattleMetadataStandards.pdf) - An analysis of City of Seattle metadata.

**Freedom of Information Act Research**

[Sunlight Foundation](https://sunlightfoundation.com/2018/10/09/research-cities-save-time-on-records-requests-by-doing-open-data-right/) FOIA's decrease if open data is done right. [Full Report](http://sunlightfoundation.com/wp-content/uploads/2018/10/alena-white-paper-PDF.pdf)

**Example open data policies**

[Witchita- permanent access](https://opendatapolicyhub.sunlightfoundation.com/collection/wichita-ks-2016-09-08/?guideline=permanent-access)

[Witchita policy](https://www.wichita.gov/IT/ITDocuments/AR%208.4%20IT%20Open%20Data%20Policy.pdf)


**Why save old data**

[Heritage Data](https://www.sciencedirect.com/science/article/pii/S2214242815000121)
